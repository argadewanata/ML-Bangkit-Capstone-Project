{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4291676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import codecs\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b81fe",
   "metadata": {},
   "source": [
    "## setup area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2c5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_filename = \"restaurant_names.txt\"\n",
    "write_filename = \"review1.csv\"\n",
    "\n",
    "read_path =os.path.join(\"response\", read_filename)\n",
    "write_path = os.path.join(\"review\",write_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169b4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kategori = ['opsi_layanan','keunggulan','aksesbilitas','penawaran',\n",
    "                'pilihan_makanan','fasilitas','suasana','tipe_pengunjung',\n",
    "                'perencanaan','pembayaran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c573c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for each category\n",
    "opsi_layanan = []\n",
    "keunggulan = []\n",
    "aksesbilitas = []\n",
    "penawaran = []\n",
    "pilihan_makanan = []\n",
    "fasilitas = []\n",
    "suasana = []\n",
    "tipe_pengunjung = []\n",
    "perencanaan = []\n",
    "pembayaran = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9e0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094a967c",
   "metadata": {},
   "source": [
    "## Google maps function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6b9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(name):\n",
    "    global driver , actions\n",
    "    global link\n",
    "    \n",
    "    link = \"https://www.google.com/maps/search/{} jogja\".format(name)\n",
    "    \n",
    "    #open up chrome and stuff\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(link)\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    #kalau gak langsung ketemu\n",
    "    \n",
    "    try:\n",
    "        restaurant_link = driver.find_elements(By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[3]/div/a')\n",
    "        \n",
    "        for links in restaurant_link:\n",
    "            link = links.get_attribute(\"href\")\n",
    "            driver.get(link)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    print('starting scraping for:{}'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef5c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def about_button():\n",
    "    about_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[3]')))\n",
    "    actions.move_to_element(about_button)\n",
    "    actions.click().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d526ee",
   "metadata": {},
   "source": [
    "## scrape about function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5ce8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_list():\n",
    "#     delay = 5\n",
    "#     #opsi layanan\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver,delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[2]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 opsi_layanan.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         opsi_layanan.append('-')\n",
    "        \n",
    "\n",
    "#     #keunggulan\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver,delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[5]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 keunggulan.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         keunggulan.append('-')\n",
    "        \n",
    "#     #aksesbilitas\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 aksesbilitas.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         aksesbilitas.append('-')\n",
    "        \n",
    "#     #penawaran\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[11]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 penawaran.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         penawaran.append('-')\n",
    "        \n",
    "#     #pilihan makanan\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[13]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 piliihan_makanan.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         pilihan_makanan.append('-')\n",
    "        \n",
    "#     #fasilitas\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[15]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 fasilitas.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         fasilitas.append('-')\n",
    "        \n",
    "#     #suasana\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[18]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 suasana.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         suasana.append('-')\n",
    "        \n",
    "#     #tipe pengunjung\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[21]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 tipe_pengunjung.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         tipe_pengunjung.append('-')\n",
    "        \n",
    "#     #perencanaan\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[24]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 perencanaan.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         perencanaan.append('-')\n",
    "        \n",
    "#     #pembayaran\n",
    "#     try:\n",
    "#         list_element = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[27]/ul')))\n",
    "        \n",
    "#         # Extract all the points from the list\n",
    "#         point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "#         # Check the class of each point and append the points with the specified class\n",
    "#         for point_element in point_elements:\n",
    "#             point_class = point_element.get_attribute(\"class\")\n",
    "#             if point_class == \"hpLkke \":\n",
    "#                 pembayaran.append(point_element.text)\n",
    "    \n",
    "#     except:\n",
    "#         pembayaran.append('-')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e358adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_list(xpath):\n",
    "    global points , number\n",
    "    points = []\n",
    "    \n",
    "    try:\n",
    "        list_element = WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.XPATH, xpath.format(number))))\n",
    "        # Extract all the points from the list\n",
    "        point_elements = list_element.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "        # Check the class of each point and append the points with the specified class\n",
    "        for point_element in point_elements:\n",
    "            point_class = point_element.get_attribute(\"class\")\n",
    "            if point_class == \"hpLkke \":\n",
    "                points.append(point_element.text)\n",
    "    \n",
    "    except:\n",
    "        points.append('-')\n",
    "        \n",
    "    number +=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bd48003",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kategori = ['opsi_layanan','keunggulan','aksesbilitas','penawaran',\n",
    "                'pilihan_makanan','fasilitas','suasana','tipe_pengunjung',\n",
    "                'perencanaan','pembayaran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ec40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_about():\n",
    "    global deskripsi , number\n",
    "    global opsi_layanan , keunggulan , aksesbilitas\n",
    "    global penawaran , pilihan_makanan , fasilitas\n",
    "    global suasana , tipe_pengunjung , perencanaan\n",
    "    global pembayaran\n",
    "    number = 2\n",
    "    xpath_deskripsi = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[{}]/p'.format(number)\n",
    "    xpath_feature = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[{}]/ul'\n",
    "    deskripsi = '-'\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    opsi_layanan = points\n",
    "\n",
    "    scrape_list(xpath_feature)\n",
    "    keunggulan = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    aksesbilitas = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    penawaran = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    pilihan_makanan = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    fasilitas = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    suasana = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    tipe_pengunjung = points\n",
    "    \n",
    "    scrape_list(xpath_feature)\n",
    "    perencanaan = points\n",
    "\n",
    "    scrape_list(xpath_feature)\n",
    "    pembayaran = points\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        raw_deskripsi = WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.XPATH, xpath_deskripsi)))\n",
    "        deskripsi = raw_deskripsi.text\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3b0af0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scraping for:'D'coff jogja\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[2]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[5]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[11]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[14]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[17]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[20]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[23]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[26]/ul\n",
      "/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[29]/ul\n",
      "['Tempat duduk di area terbuka', 'Ambil di tepi jalan', 'Pesan antar', 'Drive-through', 'Bawa pulang', 'Makan di tempat']\n"
     ]
    }
   ],
   "source": [
    "#Test cell\n",
    "\n",
    "test =\"'D'coff jogja\"\n",
    "search(test)\n",
    "about_button()\n",
    "scrape_about()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f75df",
   "metadata": {},
   "source": [
    "### setup csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ded225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fieldnames for the CSV file\n",
    "fieldnames = ['DESCRIPTION','SERVICE OPTION','HIGHLIGHTS' , 'ACCESSIBILITY' , 'OFFERINGS' , 'DINING OPTIONS' , 'AMENITIES' , 'ATHMOSPHERE', 'CROWD', 'PLANNING', 'PAYMENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4984611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scraping for:Roaster And Bear Restaurant\n",
      "feature scraping finished for Roaster And Bear Restaurant\n",
      "starting scraping for:Kalluna - Instagrammable Restaurant & Meeting Room\n",
      "feature scraping finished for Kalluna - Instagrammable Restaurant & Meeting Room\n",
      "starting scraping for:Secret Garden Coffee and Chocolate\n",
      "feature scraping finished for Secret Garden Coffee and Chocolate\n",
      "starting scraping for:Water castle cafe\n",
      "feature scraping finished for Water castle cafe\n",
      "starting scraping for:DOUBLE O Resto and Cafe\n",
      "feature scraping finished for DOUBLE O Resto and Cafe\n",
      "starting scraping for:Lecker Rumah Kopi & Resto\n",
      "feature scraping finished for Lecker Rumah Kopi & Resto\n",
      "starting scraping for:POENOKAWAN CAFE RESTO & GALLERY\n",
      "feature scraping finished for POENOKAWAN CAFE RESTO & GALLERY\n",
      "starting scraping for:Palms Resto & Cafe\n",
      "feature scraping finished for Palms Resto & Cafe\n",
      "starting scraping for:Warung Lawas\n",
      "feature scraping finished for Warung Lawas\n",
      "starting scraping for:Atap Cafe & Resto\n",
      "feature scraping finished for Atap Cafe & Resto\n",
      "starting scraping for:ViaVia Jogja\n",
      "feature scraping finished for ViaVia Jogja\n",
      "starting scraping for:Kala Jumpa\n",
      "feature scraping finished for Kala Jumpa\n",
      "starting scraping for:D'Coff Jogja\n",
      "feature scraping finished for D'Coff Jogja\n",
      "starting scraping for:Legend Coffee\n",
      "feature scraping finished for Legend Coffee\n",
      "starting scraping for:Tujuan\n",
      "feature scraping finished for Tujuan\n",
      "starting scraping for:Made Cafe\n",
      "feature scraping finished for Made Cafe\n",
      "starting scraping for:Swiss Cafe\n",
      "feature scraping finished for Swiss Cafe\n",
      "starting scraping for:RT Cafe\n",
      "feature scraping finished for RT Cafe\n",
      "starting scraping for:WRD Family Cafe\n",
      "feature scraping finished for WRD Family Cafe\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# Create the 'review' directory if it doesn't exist\n",
    "os.makedirs('feature', exist_ok=True)\n",
    "\n",
    "# Open the input file and loop through each vessel name\n",
    "with open(read_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        NAMA = row[0]\n",
    "        nomor = 1\n",
    "        review_count = 0\n",
    "\n",
    "        # Generate the write file path based on the restaurant name\n",
    "        write_filename = f\"{NAMA}.csv\"\n",
    "        write_path = os.path.join(\"feature\", write_filename)\n",
    "        \n",
    "        # Check if the file already exists and have more than 20 lines\n",
    "        if os.path.exists(write_path):\n",
    "            with open(write_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                non_empty_lines = [line for line in lines if line.strip()]  # Filter non-empty lines\n",
    "                if len(non_empty_lines) > 1:\n",
    "                    print(f\"{NAMA} is already scrapped. Check or delete the file if you want to rescrape it.\")\n",
    "                    driver.quit()  # Close the webdriver\n",
    "                    continue\n",
    "        try:\n",
    "            search(NAMA)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        about_button()\n",
    "        \n",
    "        scrape_about()\n",
    "        \n",
    "        details_dict = {\n",
    "            'DESCRIPTION': deskripsi,\n",
    "            'SERVICE OPTION': opsi_layanan,\n",
    "            'HIGHLIGHTS': keunggulan,\n",
    "            'ACCESSIBILITY': aksesbilitas,\n",
    "            'OFFERINGS': penawaran,\n",
    "            'DINING OPTIONS': pilihan_makanan,\n",
    "            'AMENITIES': fasilitas,\n",
    "            'ATHMOSPHERE': suasana,\n",
    "            'CROWD': tipe_pengunjung,\n",
    "            'PLANNING': perencanaan,\n",
    "            'PAYMENTS': pembayaran\n",
    "        }\n",
    "        \n",
    "        # Determine the maximum length among all lists\n",
    "        max_length = max(len(value) if isinstance(value, list) else 1 for value in details_dict.values())\n",
    "        \n",
    "        # Open the CSV file for writing with UTF-8 encoding\n",
    "        with codecs.open(write_path, mode='w', encoding='utf-8', errors='ignore') as details_file:\n",
    "            writer = csv.writer(details_file)\n",
    "            writer.writerow(details_dict.keys())\n",
    "            \n",
    "            # Write the data to the CSV file row-wise\n",
    "            for i in range(max_length):\n",
    "                row_data = {}\n",
    "                for key, value in details_dict.items():\n",
    "                    if isinstance(value, list) and i < len(value):\n",
    "                        row_data[key] = value[i]\n",
    "                    elif not isinstance(value, list) and i == 0:\n",
    "                        row_data[key] = value\n",
    "                    else:\n",
    "                        row_data[key] = ''\n",
    "                \n",
    "                writer.writerow(row_data.values())\n",
    "\n",
    "        print(f\"feature scraping finished for {NAMA}\")\n",
    "\n",
    "print('done!')\n",
    "driver.quit()  # Close the webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3d754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6094d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e856978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
