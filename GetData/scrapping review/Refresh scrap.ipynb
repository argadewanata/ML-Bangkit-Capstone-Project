{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0eb1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import codecs\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7542e",
   "metadata": {},
   "source": [
    "# value basic buat reset scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8bcee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1\n",
    "nomor = 1\n",
    "review_count = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a01f1",
   "metadata": {},
   "source": [
    "## masukin jumlah review yang diinginkan per restoran\n",
    "\n",
    "#### note ga semua restoran bisa punya jumlah review yang dipengen tapi nanti di print overall nya kok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "903951f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumlah_review = 25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea8c62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_filename = \"restaurant_names.txt\"\n",
    "write_filename = \"review1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4090f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path =os.path.join(\"response\", read_filename)\n",
    "write_path = os.path.join(\"review\",write_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc042e0b",
   "metadata": {},
   "source": [
    "#### function standar buat ngubah range (kelipatan 3+1 makanya gitu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5a1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changerange(basic):\n",
    "    global nomor\n",
    "    nomor = basic + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12509dd6",
   "metadata": {},
   "source": [
    "#### function buat misahin experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32efd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_string(string):\n",
    "    global experience\n",
    "    global num_of_review\n",
    "    pattern = r'^(.*?)\\s·\\s(.*)$'\n",
    "    match = re.match(pattern, string)\n",
    "    if match:\n",
    "        experience = match.group(1).strip()\n",
    "        num_of_review = match.group(2).strip()\n",
    "    else:\n",
    "        experience = '-'\n",
    "        num_of_review = string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cb66b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local guide\n",
      "48 ulasan\n"
     ]
    }
   ],
   "source": [
    "latihan = 'local guide  · 48 ulasan'\n",
    "\n",
    "separate_string(latihan)\n",
    "\n",
    "print(experience)\n",
    "print(num_of_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef035b",
   "metadata": {},
   "source": [
    "# function search\n",
    "\n",
    "### buat buka gmaps berdasarkan nama restaurantnya , gak dipake default gmaps soalnya suka error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b053039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(name):\n",
    "    global driver , actions\n",
    "    global link\n",
    "    \n",
    "    link = \"https://www.google.com/maps/search/{} jogja\".format(name)\n",
    "    \n",
    "    #open up chrome and stuff\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(link)\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    #kalau gak langsung ketemu\n",
    "    \n",
    "    try:\n",
    "        restaurant_link = driver.find_elements(By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]/div[3]/div/a')\n",
    "        \n",
    "        for links in restaurant_link:\n",
    "            link = links.get_attribute(\"href\")\n",
    "            driver.get(link)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    # Ulasan button\n",
    "    review_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[2]')))\n",
    "    actions.move_to_element(review_button)\n",
    "    actions.click().perform()\n",
    "\n",
    "    # Click on the target element\n",
    "    target_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[7]/div[1]/div[1]/div[1]')))\n",
    "    target_element.click()\n",
    "\n",
    "    # Press the down arrow key multiple times\n",
    "    for _ in range(1500):  # Adjust the number of times to press the down arrow key as needed\n",
    "        actions.send_keys(Keys.ARROW_DOWN).perform()\n",
    "        \n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "    \n",
    "    print('starting scraping for:{}'.format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8196a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scraping for:'D'coff jogja\n"
     ]
    }
   ],
   "source": [
    "# test =\"'D'coff jogja\"\n",
    "\n",
    "# search(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa2bf6",
   "metadata": {},
   "source": [
    "# function star counter buat ngitung bintang yang dikasih reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0d05aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stars(stars_xpath):\n",
    "    global empty_star_count\n",
    "    global filled_star_count\n",
    "    \n",
    "    empty_star_count = 0\n",
    "    filled_star_count = 0\n",
    "    base_star = 0\n",
    "    empty_star_class = \"https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_empty_14.png\"\n",
    "    filled_star_class = \"https://maps.gstatic.com/consumer/images/icons/2x/ic_star_rate_14.png\"\n",
    "    \n",
    "    for i in range(5):\n",
    "        base_star += 1\n",
    "        final_xpath = '{}[{}]'.format(stars_xpath, base_star)\n",
    "        \n",
    "        try:\n",
    "            stars = driver.find_elements(By.XPATH, final_xpath)\n",
    "\n",
    "            for star in stars:\n",
    "                class_name = star.get_attribute(\"src\")\n",
    "\n",
    "                if class_name == empty_star_class:\n",
    "                    empty_star_count += 1\n",
    "                elif class_name == filled_star_class:\n",
    "                    filled_star_count += 1\n",
    "        except Exception as e:\n",
    "            print('An error occurred during star counting:', str(e))\n",
    "    \n",
    "    return empty_star_count, filled_star_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b503b5",
   "metadata": {},
   "source": [
    "## function buat ngescrap review sendiri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ca4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1\n",
    "def review_scrap():\n",
    "    global name, time_of_review, num_of_review, experience, review, filled_star_count, review_count, xpath_name\n",
    "\n",
    "    xpath_review = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[4]/div[2]/div/span[1]'.format(\n",
    "        str(nomor))\n",
    "    xpath_name = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[2]/div[2]/div[1]/button/div[1]'.format(\n",
    "        str(nomor))\n",
    "    xpath_button = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[4]/div[2]/div/span[2]/button'.format(\n",
    "        str(nomor))\n",
    "    xpath_star = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[4]/div[1]/span[1]/img'.format(\n",
    "        str(nomor))\n",
    "    xpath_exp = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[2]/div[2]/div[1]/button/div[2]'.format(\n",
    "        str(nomor))\n",
    "    xpath_time = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[9]/div[{}]/div/div/div[4]/div[1]/span[2]'.format(\n",
    "        str(nomor))\n",
    "\n",
    "    # show more review\n",
    "    try:\n",
    "        maximize_button = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, xpath_button)))\n",
    "        actions.move_to_element(maximize_button)\n",
    "        actions.click().perform()\n",
    "    except:\n",
    "        try:\n",
    "            xpath_button = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[4]/div[2]/div/span[2]/button'.format(\n",
    "                str(nomor))\n",
    "            maximize_button = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, xpath_button)))\n",
    "            actions.move_to_element(maximize_button)\n",
    "            actions.click().perform()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # just believe me when I type this, somehow they change sometimes AAAAAAAAAAAAAAAAAAAAA\n",
    "    try:\n",
    "        raw_name = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, xpath_name)))\n",
    "        raw_time = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, xpath_time)))\n",
    "    except:\n",
    "        xpath_name = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[2]/div[2]/div[1]/button/div[1]'.format(\n",
    "            str(nomor))\n",
    "        \n",
    "        xpath_star = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[4]/div[1]/span[1]/img'.format(\n",
    "            str(nomor))\n",
    "        \n",
    "        raw_name = WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, xpath_name)))\n",
    "\n",
    "        xpath_time = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[4]/div[1]/span[2]'.format(\n",
    "            str(nomor))\n",
    "        \n",
    "        raw_time = WebDriverWait(driver,  delay).until(EC.presence_of_element_located((By.XPATH, xpath_time)))\n",
    "\n",
    "    name = raw_name.text\n",
    "    time_of_review = raw_time.text\n",
    "\n",
    "    try:\n",
    "        global experience, num_of_review\n",
    "\n",
    "        try:\n",
    "            raw_exp = WebDriverWait(driver,  delay).until(EC.presence_of_element_located((By.XPATH, xpath_exp)))\n",
    "            raw_review = WebDriverWait(driver,  delay).until(EC.presence_of_element_located((By.XPATH, xpath_review)))\n",
    "        except:\n",
    "            xpath_exp = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[2]/div[2]/div[1]/button/div[2]'.format(\n",
    "                str(nomor))\n",
    "            raw_exp = WebDriverWait(driver,  delay).until(EC.presence_of_element_located((By.XPATH, xpath_exp)))\n",
    "\n",
    "            xpath_review = '/html/body/div[3]/div[9]/div[9]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div[8]/div[{}]/div/div/div[4]/div[2]/div/span[1]'.format(\n",
    "                str(nomor))\n",
    "            raw_review = WebDriverWait(driver,  delay).until(EC.presence_of_element_located((By.XPATH, xpath_review)))\n",
    "\n",
    "        exp = raw_exp.text\n",
    "\n",
    "        separate_string(exp)\n",
    "        review = raw_review.text\n",
    "    except:\n",
    "        review = ''\n",
    "        experience = ''\n",
    "        num_of_review = ''\n",
    "\n",
    "    count_stars(xpath_star)\n",
    "\n",
    "    review_count += 1\n",
    "\n",
    "    # Uncomment the print statements below for debugging purposes\n",
    "#     print(\"====================\")\n",
    "#     print(f\"Reviewer: {name}\")\n",
    "#     print(f\"time of review : {time_of_review} \")\n",
    "#     print(f\"exp: {experience}\")\n",
    "#     print(f\"num: {num_of_review}\")\n",
    "#     print(f\"Review: {review}\")\n",
    "#     print(f\"Star:{filled_star_count}\")\n",
    "#     print(f\"empty Star:{empty_star_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bec9a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 1\n",
    "nomor = 1\n",
    "review_count = 0\n",
    "experience = ''\n",
    "num_of_review = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "874826a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fieldnames for the CSV file\n",
    "fieldnames = ['PLACE NAME','LINK','TIME', 'NAME', 'EXPERIENCE', 'NUMBER OF REVIEW', 'REVIEW', 'STAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9dd9e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roaster And Bear Restaurant is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Kalluna - Instagrammable Restaurant & Meeting Room is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Secret Garden Coffee and Chocolate is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Water castle cafe is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "DOUBLE O Resto and Cafe is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Lecker Rumah Kopi & Resto is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "POENOKAWAN CAFE RESTO & GALLERY is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Palms Resto & Cafe is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Warung Lawas is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Atap Cafe & Resto is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "ViaVia Jogja is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Kala Jumpa is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "D'Coff Jogja is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "Legend Coffee is already scrapped. Check or delete the file if you want to rescrape it.\n",
      "starting scraping for:Made Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping reviews for Made Cafe: 100%|███████████████████████████████████████| 25/25 [00:50<00:00,  2.03s/it, Review=25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review scraping finished for Made Cafe\n",
      "starting scraping for:Swiss Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping reviews for Swiss Cafe: 100%|██████████████████████████████████████| 25/25 [01:04<00:00,  2.59s/it, Review=25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review scraping finished for Swiss Cafe\n",
      "starting scraping for:RT Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping reviews for RT Cafe: 100%|█████████████████████████████████████████| 25/25 [00:30<00:00,  1.22s/it, Review=25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review scraping finished for RT Cafe\n",
      "starting scraping for:WRD Family Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping reviews for WRD Family Cafe: 100%|█████████████████████████████████| 25/25 [01:50<00:00,  4.40s/it, Review=25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review scraping finished for WRD Family Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "# Create the 'review' directory if it doesn't exist\n",
    "os.makedirs('review', exist_ok=True)\n",
    "\n",
    "# Open the input file and loop through each vessel name\n",
    "with open(read_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        NAMA = row[0]\n",
    "        nomor = 1\n",
    "        review_count = 0\n",
    "\n",
    "        # Generate the write file path based on the restaurant name\n",
    "        write_filename = f\"{NAMA}.csv\"\n",
    "        write_path = os.path.join(\"review\", write_filename)\n",
    "\n",
    "        # Check if the file already exists and have more than 20 lines\n",
    "        if os.path.exists(write_path):\n",
    "            with open(write_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                non_empty_lines = [line for line in lines if line.strip()]  # Filter non-empty lines\n",
    "                if len(non_empty_lines) > 20:\n",
    "                    print(f\"{NAMA} is already scrapped. Check or delete the file if you want to rescrape it.\")\n",
    "                    driver.quit()  # Close the webdriver\n",
    "                    continue\n",
    "        try:\n",
    "            search(NAMA)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Open the CSV file for writing with UTF-8 encoding\n",
    "        with codecs.open(write_path, mode='w', encoding='utf-8', errors='ignore') as details_file:\n",
    "            writer = csv.DictWriter(details_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # Write the name and link as separate rows\n",
    "            writer.writerow({'PLACE NAME': NAMA})\n",
    "            writer.writerow({'LINK': link})\n",
    "            writer.writerow({})  # Empty row for separation\n",
    "\n",
    "            # Write the column headers\n",
    "            writer.writerow({\n",
    "                'TIME': 'TIME',\n",
    "                'NAME': 'NAME',\n",
    "                'EXPERIENCE': 'EXPERIENCE',\n",
    "                'NUMBER OF REVIEW': 'NUMBER OF REVIEW',\n",
    "                'REVIEW': 'REVIEW',\n",
    "                'STAR': 'STAR'\n",
    "            })\n",
    "\n",
    "            # Use tqdm to create a progress bar\n",
    "            progress_bar = tqdm(range(jumlah_review), desc=f\"Scraping reviews for {NAMA}\")\n",
    "\n",
    "            for x in progress_bar:\n",
    "                try:\n",
    "                    review_scrap()\n",
    "                    changerange(nomor)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                details_dict = {\n",
    "                    'TIME': time_of_review,\n",
    "                    'NAME': name,\n",
    "                    'EXPERIENCE': experience,\n",
    "                    'NUMBER OF REVIEW': num_of_review,\n",
    "                    'REVIEW': review,\n",
    "                    'STAR': filled_star_count\n",
    "                }\n",
    "\n",
    "                writer.writerow(details_dict)\n",
    "\n",
    "                # Update the progress bar\n",
    "                progress_bar.set_postfix({'Review': x + 1})\n",
    "\n",
    "            # Close the progress bar\n",
    "            progress_bar.close()\n",
    "\n",
    "            print(f\"Review scraping finished for {NAMA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xpath_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2481687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "564779a5",
   "metadata": {},
   "source": [
    "# test cell buat scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "nama = 'Jogja Festival Resto And Fun Cafe'\n",
    "search(nama)\n",
    "\n",
    "for x in range(jumlah_review):\n",
    "    review_scrap()\n",
    "    changerange(nomor)\n",
    "    details_dict = {'NAME': name, 'REVIEW': review}\n",
    "\n",
    "print(f\"Total Reviews: {review_count}\")\n",
    "#driver.quit()  # Close the webdriver"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
